{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrmrP4KJQt7cKgHrJN2tHx"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from fastai.metrics import accuracy,rmse\n",
        "from rfpimp import *\n",
        "import math\n",
        "import torch\n",
        "\n",
        "\n",
        "def r_mse(x,y):\n",
        "  return round(rmse(torch.tensor(x),torch.tensor(y)).item(),6)\n",
        "\n",
        "class Randomforest():\n",
        "  def __init__(self,**kwargs):\n",
        "    self.n_estimators=kwargs['n_estimators']\n",
        "    self.min_samples_leaf=kwargs['min_samples_leaf']\n",
        "    self.max_samples=kwargs['max_samples']\n",
        "    self.max_features=kwargs['max_features']\n",
        "    self.n_jobs=kwargs['n_jobs']\n",
        "    self.oob_score=kwargs['oob_score']\n",
        "\n",
        "  def model(self,x,y):\n",
        "    self.model=RandomForestRegressor(n_estimators=self.n_estimators,min_samples_leaf=self.min_samples_leaf\n",
        "                               ,max_samples=self.max_samples,max_features=self.max_features\n",
        "                               ,n_jobs=self.n_jobs,oob_score=self.oob_score)\n",
        "    self.fit=self.model.fit(x,y)\n",
        "    return self.fit\n",
        "  \n",
        "  def model_rmse(self,x,y):\n",
        "    #r_mse1=round(math.sqrt(((self.m.predict(x)-y)**2).mean()),6)\n",
        "    self.root_mse=r_mse(self.fit.predict(x),y)\n",
        "    return print('mse:  ',self.root_mse)\n",
        "  \n",
        "  def model_accuracy(self,x,y):\n",
        "    return print('accuracy:  ',1-self.root_mse)\n",
        "  \n",
        "  def importance(self,x,y):\n",
        "    imp=importances(self.model,x,y)\n",
        "    return plot_importances(imp)\n",
        "  \n",
        "  def prediction(self,x):\n",
        "    return self.model.predict(x)\n",
        "\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost import plot_importance\n",
        "class xgbreg(Randomforest):\n",
        "  def __init__(self,**kwargs):\n",
        "    self.n_estimators =kwargs['n_estimators'] \n",
        "    self.max_depth=kwargs['max_depth'] \n",
        "    self.learning_rate=kwargs['learning_rate'] \n",
        "    self.n_jobs=kwargs['n_jobs']\n",
        "    self.early_stopping_rounds=kwargs['early_stopping_rounds']\n",
        "    self.subsample=kwargs['subsample']\n",
        "  def model(self,x,y):\n",
        "    self.model=xgb.XGBRegressor(n_estimators=self.n_estimators,learning_rate =self.learning_rate,\n",
        "                    max_depth =self.max_depth,n_jobs =self.n_jobs,\n",
        "                    early_stopping_rounds=self.early_stopping_rounds,subsample=self.subsample)\n",
        "    self.fit=self.model.fit(x,y)\n",
        "    return self.fit\n",
        "  def model_rmse(self, x, y):\n",
        "    return super().model_rmse(x, y)\n",
        "  def model_accuracy(self, x, y):\n",
        "    return super().model_accuracy(x, y)\n",
        "  def prediction(self, x):\n",
        "    return super().prediction(x)\n",
        "    #return predict(self.model,x)\n",
        "  def importance(self):\n",
        "    return plot_importance(self.model)\n",
        "\n",
        "\n",
        "class NN():\n",
        "  def __init__(self,to,layers=[200,100]):\n",
        "    self.dls=to.dataloaders()\n",
        "    self.layers=layers\n",
        "    self.y_range=(int(to.train.y.min()),int(to.train.y.max())+1)\n",
        "    self.tc = tabular_config(ps=[0.001, 0.01], embed_p=0.04)\n",
        "    self.callbacks=[SaveModelCallback(monitor='_rmse',comp=np.less,fname='nnlearner')]\n",
        "    self.learn=tabular_learner(self.dls,y_range=self.y_range,layers=self.layers,config=self.tc,\n",
        "                              loss_func=F.mse_loss,metrics=rmse)  \n",
        "  def train(self,lr):\n",
        "    return self.learn.fit_one_cycle(50,lr,cbs=self.callbacks)\n",
        "\n",
        "  def predict(self):   \n",
        "    return self.learn.get_preds()[0]\n",
        "  def importance(self):\n",
        "    return PermutationImportance(self.learn)\n",
        "  \n",
        "\n",
        "def implement(m,to):\n",
        "  xs,y=to.train.xs,to.train.y.ravel()\n",
        "  valid_xs,valid_y=to.valid.xs,to.valid.y.ravel()\n",
        "  m.model(xs,y)\n",
        "  print('train>>>')\n",
        "  m.model_rmse(xs,y)\n",
        "  m.model_accuracy(xs,y)\n",
        "  print('valid>>>')\n",
        "  m.model_rmse(valid_xs,valid_y)\n",
        "  m.model_accuracy(valid_xs,valid_y)\n",
        "  return m.prediction(valid_xs)\n",
        "\n",
        "class PermutationImportance():\n",
        "  \"Calculate and plot the permutation importance\"\n",
        "  def __init__(self, learn:Learner, df=None, bs=None):\n",
        "    \"Initialize with a test dataframe, a learner, and a metric\"\n",
        "    self.learn = learn\n",
        "    self.df = df if df is not None else None\n",
        "    bs = bs if bs is not None else learn.dls.bs\n",
        "    self.dl = learn.dls.test_dl(self.df, bs=bs) if self.df is not None else learn.dls[1]\n",
        "    self.x_names = learn.dls.x_names.filter(lambda x: '_na' not in x)\n",
        "    self.na = learn.dls.x_names.filter(lambda x: '_na' in x)\n",
        "    self.y = learn.dls.y_names\n",
        "    self.results = self.calc_feat_importance()\n",
        "    self.plot_importance(self.ord_dic_to_df(self.results))\n",
        "\n",
        "  def measure_col(self, name:str):\n",
        "    \"Measures change after column shuffle\"\n",
        "    col = [name]\n",
        "    if f'{name}_na' in self.na: col.append(name)\n",
        "    orig = self.dl.items[col].values\n",
        "    perm = np.random.permutation(len(orig))\n",
        "    self.dl.items[col] = self.dl.items[col].values[perm]\n",
        "    metric = self.learn.validate(dl=self.dl)[1]\n",
        "    self.dl.items[col] = orig\n",
        "    return metric\n",
        "\n",
        "  def calc_feat_importance(self):\n",
        "    \"Calculates permutation importance by shuffling a column on a percentage scale\"\n",
        "    print('Getting base error')\n",
        "    base_error = self.learn.validate(dl=self.dl)[1]\n",
        "    self.importance = {}\n",
        "    pbar = progress_bar(self.x_names)\n",
        "    print('Calculating Permutation Importance')\n",
        "    for col in pbar:\n",
        "      self.importance[col] = self.measure_col(col)\n",
        "    for key, value in self.importance.items():\n",
        "      self.importance[key] = (base_error-value)/base_error #this can be adjusted\n",
        "    return OrderedDict(sorted(self.importance.items(), key=lambda kv: kv[1], reverse=True))\n",
        "\n",
        "  def ord_dic_to_df(self, dict:OrderedDict):\n",
        "    return pd.DataFrame([[k, v] for k, v in dict.items()], columns=['feature', 'importance'])\n",
        "\n",
        "  def plot_importance(self, df:pd.DataFrame, limit=20, asc=False, **kwargs):\n",
        "    \"Plot importance with an optional limit to how many variables shown\"\n",
        "    df_copy = df.copy()\n",
        "    df_copy['feature'] = df_copy['feature'].str.slice(0,25)\n",
        "    df_copy = df_copy.sort_values(by='importance', ascending=asc)[:limit].sort_values(by='importance', ascending=not(asc))\n",
        "    ax = df_copy.plot.barh(x='feature', y='importance', sort_columns=True, **kwargs)\n",
        "    for p in ax.patches:\n",
        "      ax.annotate(f'{p.get_width():.4f}', ((p.get_width() * 1.005), p.get_y()  * 1.005))"
      ],
      "metadata": {
        "id": "99adHQ50Qt3c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}